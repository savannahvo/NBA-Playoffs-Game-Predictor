{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a59642-7361-45ec-963f-2775139dd525",
   "metadata": {},
   "source": [
    "## Model Training, Evaluation, and Saving\n",
    "\n",
    "This section trains, evaluates, and selects the best-performing machine learning model for predicting NBA playoff game outcomes.  \n",
    "It loads processed features and labels, compares multiple models, selects the best based on **F1 Score**, retrains it using all available training data, and saves both the final model and predictions.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why the Best Model Was Chosen Using F1 Score\n",
    "In predicting playoff outcomes, **class imbalance** can occur, and some teams (like #1 seeds) win more often than underdogs. If we only optimized for accuracy, the model could favor predicting favorites and still achieve a decent score, while missing many true upsets.\n",
    "\n",
    "- **Precision** -> Of all the games predicted as wins, how many were correct?\n",
    "- **Recall** -> Of all the actual wins, how many did the model catch?\n",
    "- **F1 Score** -> THe harmonic mean of precision and recall, balancing both.\n",
    "\n",
    "By prioritizing **F1 Score**, I ensured the chosen model performed well not just at prediciting favorites, but also at identifying underdog wins. This makes the model more reliable in playoff settings where unexpected outcomes are common and more valuable to analysts who care about both predicting favorites and catching upsets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee264a74-c118-4994-9a1d-538ee86f1f4a",
   "metadata": {},
   "source": [
    "##### Key Steps:\n",
    "1. **Import Libraries**: Load Scikit-learn classifiers, metrics, and utilities for training and evaluation.\n",
    "2. **Load Processed Data**: Import preprocessed train/validation/test splits created in Notebook 3.\n",
    "3. **Train Candidate Models**: Fit multiple classifiers, including Logistic Regression, Random Forest, Gradient Boosting, and Support Vector Machines (SVM).\n",
    "4. **Evaluate Models**: Compute accuracy, precision, recall, and F1 score on the validation set.\n",
    "5. **Select Best Model**: Choose the model that best balances false positives and false negatives (highest F1 score).\n",
    "6. **Test on 2025 Data**: Evaluate the final model on the held-out test set (2025 playoffs) to simulate real-world forecasting.\n",
    "7. **Save Best Model**: Export the trained model with joblib for use in the simulator application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b173551-7eb9-40fa-9661-0a8913d6542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "Accuracy : 0.5119\n",
      "Precision: 0.5660\n",
      "Recall   : 0.6250\n",
      "F1 Score : 0.5941\n",
      "----------------------------------------\n",
      "RandomForest:\n",
      "Accuracy : 0.5595\n",
      "Precision: 0.6000\n",
      "Recall   : 0.6875\n",
      "F1 Score : 0.6408\n",
      "----------------------------------------\n",
      "GradientBoosting:\n",
      "Accuracy : 0.5714\n",
      "Precision: 0.6034\n",
      "Recall   : 0.7292\n",
      "F1 Score : 0.6604\n",
      "----------------------------------------\n",
      "SVM:\n",
      "Accuracy : 0.5952\n",
      "Precision: 0.6129\n",
      "Recall   : 0.7917\n",
      "F1 Score : 0.6909\n",
      "----------------------------------------\n",
      "\n",
      "Model Comparison:\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  LogisticRegression  0.511905   0.566038  0.625000  0.594059\n",
      "1        RandomForest  0.559524   0.600000  0.687500  0.640777\n",
      "2    GradientBoosting  0.571429   0.603448  0.729167  0.660377\n",
      "3                 SVM  0.595238   0.612903  0.791667  0.690909\n",
      "\n",
      "Best model based on F1 Score: SVM\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load Processed Feature Sets and Labels\n",
    "X_train = pd.read_csv(\"../data/processed/X_train_processed.csv\")\n",
    "X_val   = pd.read_csv(\"../data/processed/X_val_processed.csv\")\n",
    "X_test  = pd.read_csv(\"../data/processed/X_test_processed.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").values.ravel()\n",
    "y_val   = pd.read_csv(\"../data/processed/y_val.csv\").values.ravel()\n",
    "y_test  = pd.read_csv(\"../data/processed/y_test.csv\").values.ravel()\n",
    "\n",
    "# Combine Training + Validation\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = pd.concat([pd.Series(y_train), pd.Series(y_val)], axis=0).values\n",
    "\n",
    "# Define Evaluation Function\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    # Evaluate model performance and print metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# Define & Evaluate Multiple Models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"clf\", clf)])\n",
    "    pipe.fit(X_train_val, y_train_val)\n",
    "    acc, prec, rec, f1 = evaluate_model(name, pipe, X_test, y_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\\n\", results_df)\n",
    "\n",
    "# Select Best Model Based on F1 Score\n",
    "best_model_name = results_df.sort_values(by=\"F1 Score\", ascending=False).iloc[0][\"Model\"]\n",
    "print(f\"\\nBest model based on F1 Score: {best_model_name}\")\n",
    "\n",
    "best_clf = models[best_model_name]\n",
    "\n",
    "# Retrain Best Model on All Train+Val Data\n",
    "final_pipe = Pipeline([(\"clf\", best_clf)])\n",
    "final_pipe.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(final_pipe, f\"../model/final_{best_model_name.lower()}_model.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(X_train.columns.tolist(), \"../model/modeled_features.pkl\")\n",
    "\n",
    "# Make Predictions with Final Model\n",
    "final_model = joblib.load(f\"../model/final_{best_model_name.lower()}_model.pkl\")\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"true_label\": y_test,\n",
    "    \"predicted_label\": y_pred\n",
    "})\n",
    "predictions_df.to_csv(f\"../model/{best_model_name.lower()}_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
