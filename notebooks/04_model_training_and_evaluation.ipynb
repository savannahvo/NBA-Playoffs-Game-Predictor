{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a59642-7361-45ec-963f-2775139dd525",
   "metadata": {},
   "source": [
    "## Model Training, Evaluation, and Saving\n",
    "\n",
    "This section trains, evaluates, and selects the best-performing machine learning model for predicting NBA playoff game outcomes.  \n",
    "It loads processed features and labels, compares multiple models, selects the best based on **F1 Score**, retrains it using all available training data, and saves both the final model and predictions.\n",
    "\n",
    "##### Overview of Steps:\n",
    "1. **Import Libraries**: Load data handling (`pandas`), machine learning models (`LogisticRegression`, `RandomForestClassifier`, `GradientBoostingClassifier`, `SVC`), evaluation metrics, and utilities for saving/loading models.\n",
    "2. **Load Processed Data**: Read preprocessed feature sets (`X_train`, `X_val`, `X_test`) and labels (`y_train`, `y_val`, `y_test`) from the `processed` directory.\n",
    "3. **Combine Training and Validation Sets**: Merge `X_train` and `X_val` into a single training set for final model training, ensuring the model uses all available pre-test data.\n",
    "4. **Define Evaluation Function**: Create a reusable function `evaluate_model()` to train a model, make predictions, and print Accuracy, Precision, Recall, and F1 Score.\n",
    "5. **Define and Evaluate Multiple Models**: Train and evaluate four models — Logistic Regression, Random Forest, Gradient Boosting, and SVM — on the combined training set, recording performance metrics on the test set.\n",
    "6. **Compare Models and Select the Best**: Compare results in a DataFrame and choose the highest F1 Score model as the final model.\n",
    "7. **Retrain Best Model**: Retrain the selected model on the full combined training + validation data to maximize performance.\n",
    "8. **Save Model and Features**: Save the trained model (`.pkl`) and the list of feature names used during training for consistent future predictions.\n",
    "9. **Make Predictions and Save Results**: Use the final model to predict outcomes on the test set, then save predictions (`true_label` and `predicted_label`) to the `final` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b173551-7eb9-40fa-9661-0a8913d6542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "Accuracy : 0.5119\n",
      "Precision: 0.5660\n",
      "Recall   : 0.6250\n",
      "F1 Score : 0.5941\n",
      "----------------------------------------\n",
      "RandomForest:\n",
      "Accuracy : 0.5595\n",
      "Precision: 0.6000\n",
      "Recall   : 0.6875\n",
      "F1 Score : 0.6408\n",
      "----------------------------------------\n",
      "GradientBoosting:\n",
      "Accuracy : 0.5714\n",
      "Precision: 0.6034\n",
      "Recall   : 0.7292\n",
      "F1 Score : 0.6604\n",
      "----------------------------------------\n",
      "SVM:\n",
      "Accuracy : 0.5952\n",
      "Precision: 0.6129\n",
      "Recall   : 0.7917\n",
      "F1 Score : 0.6909\n",
      "----------------------------------------\n",
      "\n",
      "Model Comparison:\n",
      "                 Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  LogisticRegression  0.511905   0.566038  0.625000  0.594059\n",
      "1        RandomForest  0.559524   0.600000  0.687500  0.640777\n",
      "2    GradientBoosting  0.571429   0.603448  0.729167  0.660377\n",
      "3                 SVM  0.595238   0.612903  0.791667  0.690909\n",
      "\n",
      "Best model based on F1 Score: SVM\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Load Processed Feature Sets and Labels\n",
    "X_train = pd.read_csv(\"../data/processed/X_train_processed.csv\")\n",
    "X_val   = pd.read_csv(\"../data/processed/X_val_processed.csv\")\n",
    "X_test  = pd.read_csv(\"../data/processed/X_test_processed.csv\")\n",
    "\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").values.ravel()\n",
    "y_val   = pd.read_csv(\"../data/processed/y_val.csv\").values.ravel()\n",
    "y_test  = pd.read_csv(\"../data/processed/y_test.csv\").values.ravel()\n",
    "\n",
    "# Combine Training + Validation\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = pd.concat([pd.Series(y_train), pd.Series(y_val)], axis=0).values\n",
    "\n",
    "# Define Evaluation Function\n",
    "def evaluate_model(name, model, X_test, y_test):\n",
    "    # Evaluate model performance and print metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")\n",
    "    print(f\"F1 Score : {f1:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    return acc, prec, rec, f1\n",
    "\n",
    "# Define & Evaluate Multiple Models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"clf\", clf)])\n",
    "    pipe.fit(X_train_val, y_train_val)\n",
    "    acc, prec, rec, f1 = evaluate_model(name, pipe, X_test, y_test)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nModel Comparison:\\n\", results_df)\n",
    "\n",
    "# Select Best Model Based on F1 Score\n",
    "best_model_name = results_df.sort_values(by=\"F1 Score\", ascending=False).iloc[0][\"Model\"]\n",
    "print(f\"\\nBest model based on F1 Score: {best_model_name}\")\n",
    "\n",
    "best_clf = models[best_model_name]\n",
    "\n",
    "# Retrain Best Model on All Train+Val Data\n",
    "final_pipe = Pipeline([(\"clf\", best_clf)])\n",
    "final_pipe.fit(X_train_val, y_train_val)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(final_pipe, f\"../model/final_{best_model_name.lower()}_model.pkl\")\n",
    "\n",
    "# Save feature names\n",
    "joblib.dump(X_train.columns.tolist(), \"../model/modeled_features.pkl\")\n",
    "\n",
    "# Make Predictions with Final Model\n",
    "final_model = joblib.load(f\"../model/final_{best_model_name.lower()}_model.pkl\")\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"true_label\": y_test,\n",
    "    \"predicted_label\": y_pred\n",
    "})\n",
    "predictions_df.to_csv(f\"../model/{best_model_name.lower()}_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975a42b-b533-4965-9eb4-454d04759f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
